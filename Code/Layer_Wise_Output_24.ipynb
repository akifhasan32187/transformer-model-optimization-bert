{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24037,"status":"ok","timestamp":1684091279081,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"},"user_tz":-360},"id":"P14A6NQlMxqA","outputId":"f07351f9-5eb4-4606-8b78-449788591ec1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19012,"status":"ok","timestamp":1684091298082,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"},"user_tz":-360},"id":"9-n3L31fM-N-","outputId":"8fde91e6-cb43-4740-a2b3-d3af8d50f34c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DihmGNy3Ysxd"},"outputs":[],"source":["# import torch\n","# import pandas as pd\n","# import numpy as np\n","# from transformers import BertTokenizer, BertModel\n","# from torch.utils.data import Dataset, DataLoader\n","# from sklearn.metrics import accuracy_score\n","\n","# # Define the device to use for training\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# # Load the datasets\n","# train_data = pd.read_csv(\"/content/drive/MyDrive/NEEWWWWW/DATA_NEW/PC/1000/train_800.csv\")\n","# test_data = pd.read_csv(\"/content/drive/MyDrive/NEEWWWWW/DATA_NEW/PC/1000/test_200.csv\")\n","\n","# # Define the BERT model and tokenizer\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","# model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n","# model.to(device)\n","\n","# # Define the dataset class\n","# class CustomDataset(Dataset):\n","#     def __init__(self, df):\n","#         self.df = df\n","#         self.tokenizer = tokenizer\n","    \n","#     def __len__(self):\n","#         return len(self.df)\n","    \n","#     def __getitem__(self, idx):\n","#         text = self.df.iloc[idx]['text']\n","#         label = self.df.iloc[idx]['label']\n","        \n","#         inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n","#         input_ids = inputs['input_ids'].squeeze(0)\n","#         attention_mask = inputs['attention_mask'].squeeze(0)\n","        \n","#         return {'input_ids': input_ids.to(device), 'attention_mask': attention_mask.to(device), 'label': torch.tensor(label).to(device)}\n","\n","# # Define the data loaders\n","# train_dataset = CustomDataset(train_data)\n","# test_dataset = CustomDataset(test_data)\n","# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# # Define the training and testing functions\n","# def train(model, train_loader, optimizer, criterion):\n","#     model.train()\n","#     train_loss = 0\n","#     train_acc = 0\n","#     total = 0\n","    \n","#     for batch in train_loader:\n","#         input_ids = batch['input_ids']\n","#         attention_mask = batch['attention_mask']\n","#         labels = batch['label']\n","        \n","#         optimizer.zero_grad()\n","#         outputs = model(input_ids, attention_mask=attention_mask)\n","#         logits = outputs.last_hidden_state[:, 0, :]\n","#         loss = criterion(logits, labels)\n","        \n","#         loss.backward()\n","#         optimizer.step()\n","        \n","#         train_loss += loss.item() * len(input_ids)\n","#         train_acc += accuracy_score(labels.cpu().numpy(), np.argmax(logits.cpu().detach().numpy(), axis=1)) * len(input_ids)\n","#         total += len(input_ids)\n","    \n","#     return train_loss / total, train_acc / total\n","\n","# def test(model, test_loader, criterion):\n","#     model.eval()\n","#     test_loss = 0\n","#     test_acc = 0\n","#     total = 0\n","#     hidden_states = [[] for _ in range(12)]\n","    \n","#     with torch.no_grad():\n","#         for batch in test_loader:\n","#             input_ids = batch['input_ids']\n","#             attention_mask = batch['attention_mask']\n","#             labels = batch['label']\n","            \n","#             outputs = model(input_ids, attention_mask=attention_mask)\n","#             logits = outputs.last_hidden_state[:, 0, :]\n","#             loss = criterion(logits, labels)\n","            \n","#             test_loss += loss.item() * len(input_ids)\n","#             test_acc += accuracy_score(labels.cpu().numpy(), np.argmax(logits.cpu().detach().numpy(), axis=1)) * len(input_ids)\n","#             total += len(input_ids)\n","            \n","#             for i in range(12):\n","#                 hidden_states[i].append(outputs.hidden_states[i].cpu().detach().numpy())\n","    \n","#     hidden_states = [np.concatenate(layer) for layer in hidden_states]\n","    \n","#     return test_loss / total, test_acc / total, hidden_states\n","\n","# # Define the optimizer and loss function\n","# optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n","# criterion = torch.nn.CrossEntropyLoss()\n","\n","# # Train the model for 5 epochs\n","# for epoch in range(20):\n","#     train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n","#     test_loss, test_acc, hidden_states = test(model, test_loader, criterion)\n","    \n","#     print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f} - Test Loss: {test_loss:.4f} - Train Acc: {train_acc*100:.4f} - Test Acc: {test_acc*100:.4f}\")\n","    \n","    \n","#     # Save the hidden layer outputs for this epoch\n","#     for i, layer in enumerate(hidden_states):\n","#         np.save(f\"hidden_layer_{i}_train.npy\", layer) \n","\n","#     # Save the hidden layer outputs for this epoch\n","#     for i, layer in enumerate(hidden_states):\n","#         np.save(f\"hidden_layer_{i}_test.npy\", layer)       "]},{"cell_type":"code","source":["# import torch\n","# import pandas as pd\n","# import numpy as np\n","# from transformers import BertTokenizer, BertModel\n","# from torch.utils.data import Dataset, DataLoader\n","# from sklearn.metrics import accuracy_score\n","\n","# # Define the device to use for training\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# # Load the datasets\n","# train_data = pd.read_csv(\"/content/drive/MyDrive/NEEWWWWW/DATA_NEW/PC/1000/train_800.csv\")\n","# test_data = pd.read_csv(\"/content/drive/MyDrive/NEEWWWWW/DATA_NEW/PC/1000/test_200.csv\")\n","\n","# # Define the BERT model and tokenizer\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","# model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n","# model.to(device)\n","\n","# # Define the dataset class\n","# class CustomDataset(Dataset):\n","#     def __init__(self, df):\n","#         self.df = df\n","#         self.tokenizer = tokenizer\n","    \n","#     def __len__(self):\n","#         return len(self.df)\n","    \n","#     def __getitem__(self, idx):\n","#         text = self.df.iloc[idx]['text']\n","#         label = self.df.iloc[idx]['label']\n","        \n","#         inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n","#         input_ids = inputs['input_ids'].squeeze(0)\n","#         attention_mask = inputs['attention_mask'].squeeze(0)\n","        \n","#         return {'input_ids': input_ids.to(device), 'attention_mask': attention_mask.to(device), 'label': torch.tensor(label).to(device)}\n","\n","# # Define the data loaders\n","# train_dataset = CustomDataset(train_data)\n","# test_dataset = CustomDataset(test_data)\n","# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# # Define the training and testing functions\n","# def train(model, train_loader, optimizer, criterion):\n","#     model.train()\n","#     train_loss = 0\n","#     train_acc = 0\n","#     total = 0\n","#     layer_train_loss_data = []\n","#     layer_train_acc_data = []\n","    \n","#     for batch in train_loader:\n","#         input_ids = batch['input_ids']\n","#         attention_mask = batch['attention_mask']\n","#         labels = batch['label']\n","        \n","#         optimizer.zero_grad()\n","#         outputs = model(input_ids, attention_mask=attention_mask)\n","#         logits = outputs.last_hidden_state[:, 0, :]\n","#         loss = criterion(logits, labels)\n","        \n","#         loss.backward()\n","#         optimizer.step()\n","        \n","#         train_loss += loss.item() * len(input_ids)\n","#         train_acc += accuracy_score(labels.cpu().numpy(), np.argmax(logits.cpu().detach().numpy(), axis=1)) * len(input_ids)\n","#         total += len(input_ids)\n","        \n","#         for i in range(12):\n","#             # Calculate the loss and accuracy for this layer\n","#             layer_logits = outputs.hidden_states[i][:, 0, :]\n","#             layer_loss = criterion(layer_logits, labels)\n","#             layer_preds = np.argmax(layer_logits.cpu().detach().numpy(), axis=1)\n","#             layer_labels = labels.cpu().numpy()\n","#             layer_acc = accuracy_score(layer_labels, layer_preds)\n","#             layer_train_loss_data.append(layer_loss.item())\n","#             layer_train_acc_data.append(layer_acc)\n","\n","#     # Print the loss and accuracy for each layer\n","#     for i in range(12):\n","#         layer_train_loss = np.mean(layer_train_loss_data[i::12])\n","#         layer_train_acc = np.mean(layer_train_acc_data[i::12])\n","#         print(f\"Epoch {epoch+1} - Layer {i+1} - Train Loss: {layer_train_loss:.4f} - Train Acc: {layer_train_acc*100:.4f}\")\n","    \n","#     return train_loss / total, train_acc / total\n","\n","\n","# def test(model, test_loader, criterion):\n","#     model.eval()\n","#     test_loss = 0\n","#     test_acc = 0\n","#     total = 0\n","#     hidden_states = [[] for _ in range(12)]\n","#     layer_test_loss_data = []\n","#     layer_test_acc_data = []\n","    \n","#     with torch.no_grad():\n","#         for batch in test_loader:\n","#             input_ids = batch['input_ids']\n","#             attention_mask = batch['attention_mask']\n","#             labels = batch['label']\n","            \n","#             outputs = model(input_ids, attention_mask=attention_mask)\n","#             logits = outputs.last_hidden_state[:, 0, :]\n","#             loss = criterion(logits, labels)\n","            \n","#             test_loss += loss.item() * len(input_ids)\n","#             test_acc += accuracy_score(labels.cpu().numpy(), np.argmax(logits.cpu().detach().numpy(), axis=1)) * len(input_ids)\n","#             total += len(input_ids)\n","            \n","#             for i in range(12):\n","#                 hidden_states[i].append(outputs.hidden_states[i].cpu().detach().numpy())\n","                \n","#                 # Calculate the loss and accuracy for this layer\n","#                 layer_logits = outputs.hidden_states[i][:, 0, :]\n","#                 layer_loss = criterion(layer_logits, labels)\n","#                 layer_preds = np.argmax(layer_logits.cpu().detach().numpy(), axis=1)\n","#                 layer_labels = labels.cpu().numpy()\n","#                 layer_acc = accuracy_score(layer_labels, layer_preds)\n","#                 layer_test_loss_data.append(layer_loss.item())\n","#                 layer_test_acc_data.append(layer_acc)\n","\n","#     # Print the loss and accuracy for each layer\n","#     for i in range(12):\n","#         layer_test_loss = np.mean(layer_test_loss_data[i::12])\n","#         layer_test_acc = np.mean(layer_test_acc_data[i::12])\n","#         print(f\"Epoch {epoch+1} - Layer {i+1} - Test Loss: {layer_test_loss:.4f} - Test Acc: {layer_test_acc*100:.4f}\")\n","        \n","#     return test_loss / total, test_acc / total, hidden_states\n","\n","# # Define the optimizer and loss function\n","# optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n","# criterion = torch.nn.CrossEntropyLoss()\n","\n","# # Train the model for 10 epochs\n","# for epoch in range(30):\n","#     train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n","#     print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc*100:.4f}\")\n","    \n","#     test_loss, test_acc, hidden_states = test(model, test_loader, criterion)\n","#     print(f\"Epoch {epoch+1} - Test Loss: {test_loss:.4f} - Test Acc: {test_acc*100:.4f}\")"],"metadata":{"id":"3YjyOkAwS6IJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from transformers import BertTokenizer, BertModel\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import accuracy_score\n","\n","# Define the device to use for training\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device = torch.device(\"cpu\")\n","\n","# Load the datasets\n","train_data = pd.read_csv(\"/content/drive/MyDrive/NEEWWWWW/DATA_NEW/PC/1000/train_800.csv\")\n","test_data = pd.read_csv(\"/content/drive/MyDrive/NEEWWWWW/DATA_NEW/PC/1000/test_200.csv\")\n","\n","# Define the BERT model and tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n","model = BertModel.from_pretrained('bert-large-cased', output_hidden_states=True)\n","model.to(device)\n","\n","# Define the dataset class\n","class CustomDataset(Dataset):\n","    def __init__(self, df):\n","        self.df = df\n","        self.tokenizer = tokenizer\n","    \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, idx):\n","        text = self.df.iloc[idx]['text']\n","        label = self.df.iloc[idx]['label']\n","        \n","        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n","        input_ids = inputs['input_ids'].squeeze(0)\n","        attention_mask = inputs['attention_mask'].squeeze(0)\n","        \n","        return {'input_ids': input_ids.to(device), 'attention_mask': attention_mask.to(device), 'label': torch.tensor(label).to(device)}\n","\n","# Define the data loaders\n","train_dataset = CustomDataset(train_data)\n","test_dataset = CustomDataset(test_data)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Define the training and testing functions\n","def train(model, train_loader, optimizer, criterion):\n","    model.train()\n","    train_loss = 0\n","    train_acc = 0\n","    total = 0\n","    layer_train_loss_data = []\n","    layer_train_acc_data = []\n","    \n","    for batch in train_loader:\n","        input_ids = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        labels = batch['label']\n","        \n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        logits = outputs.last_hidden_state[:, 0, :]\n","        loss = criterion(logits, labels)\n","        \n","        loss.backward()\n","        optimizer.step()\n","        \n","        train_loss += loss.item() * len(input_ids)\n","        train_acc += accuracy_score(labels.cpu().numpy(), np.argmax(logits.cpu().detach().numpy(), axis=1)) * len(input_ids)\n","        total += len(input_ids)\n","        \n","        for i in range(24):\n","            # Calculate the loss and accuracy for this layer\n","            layer_logits = outputs.hidden_states[i][:, 0, :]\n","            layer_loss = criterion(layer_logits, labels)\n","            layer_preds = np.argmax(layer_logits.cpu().detach().numpy(), axis=1)\n","            layer_labels = labels.cpu().numpy()\n","            layer_acc = accuracy_score(layer_labels, layer_preds)\n","            layer_train_loss_data.append(layer_loss.item())\n","            layer_train_acc_data.append(layer_acc)\n","\n","    # Print the loss and accuracy for each layer\n","    for i in range(24):\n","        layer_train_loss = np.mean(layer_train_loss_data[i::24])\n","        layer_train_acc = np.mean(layer_train_acc_data[i::24])\n","        print(f\"Epoch {epoch+1} - Layer {i+1} - Train Loss: {layer_train_loss:.4f} - Train Acc: {layer_train_acc*100:.4f}\")\n","    \n","    return train_loss / total, train_acc / total\n","\n","\n","def test(model, test_loader, criterion):\n","    model.eval()\n","    test_loss = 0\n","    test_acc = 0\n","    total = 0\n","    hidden_states = [[] for _ in range(24)]\n","    layer_test_loss_data = []\n","    layer_test_acc_data = []\n","    \n","    with torch.no_grad():\n","        for batch in test_loader:\n","            input_ids = batch['input_ids']\n","            attention_mask = batch['attention_mask']\n","            labels = batch['label']\n","            \n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            logits = outputs.last_hidden_state[:, 0, :]\n","            loss = criterion(logits, labels)\n","            \n","            test_loss += loss.item() * len(input_ids)\n","            test_acc += accuracy_score(labels.cpu().numpy(), np.argmax(logits.cpu().detach().numpy(), axis=1)) * len(input_ids)\n","            total += len(input_ids)\n","            \n","            for i in range(24):\n","                hidden_states[i].append(outputs.hidden_states[i].cpu().detach().numpy())\n","                \n","                # Calculate the loss and accuracy for this layer\n","                layer_logits = outputs.hidden_states[i][:, 0, :]\n","                layer_loss = criterion(layer_logits, labels)\n","                layer_preds = np.argmax(layer_logits.cpu().detach().numpy(), axis=1)\n","                layer_labels = labels.cpu().numpy()\n","                layer_acc = accuracy_score(layer_labels, layer_preds)\n","                layer_test_loss_data.append(layer_loss.item())\n","                layer_test_acc_data.append(layer_acc)\n","\n","    # Print the loss and accuracy for each layer\n","    for i in range(24):\n","        layer_test_loss = np.mean(layer_test_loss_data[i::24])\n","        layer_test_acc = np.mean(layer_test_acc_data[i::24])\n","        print(f\"Epoch {epoch+1} - Layer {i+1} - Test Loss: {layer_test_loss:.4f} - Test Acc: {layer_test_acc*100:.4f}\")\n","        \n","    return test_loss / total, test_acc / total, hidden_states\n","\n","# Define the optimizer and loss function\n","optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# Train the model for 30 epochs\n","train_losses = []\n","train_accs = []\n","test_losses = []\n","test_accs = []\n","\n","for epoch in range(10):\n","    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n","    print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc*100:.4f}\")\n","    train_losses.append(train_loss)\n","    train_accs.append(train_acc)\n","    \n","    test_loss, test_acc, hidden_states = test(model, test_loader, criterion)\n","    print(f\"Epoch {epoch+1} - Test Loss: {test_loss:.4f} - Test Acc: {test_acc*100:.4f}\")\n","    test_losses.append(test_loss)\n","    test_accs.append(test_acc)\n","\n","    # Plot the train and test losses and accuracies\n","    fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n","    axs[0, 0].plot(train_losses)\n","    axs[0, 0].set_title('Train Loss')\n","    axs[0, 1].plot(train_accs)\n","    axs[0, 1].set_title('Train Accuracy')\n","    axs[1, 0].plot(test_losses)\n","    axs[1, 0].set_title('Test Loss')\n","    axs[1, 1].plot(test_accs)\n","    axs[1, 1].set_title('Test Accuracy')\n","    plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["ad25fe701fad4c1fad7f91aa34b0543e","64bbb86a1c1b44a3aaeb523975b52734","4e4afd134a554c17af6262ad48d45660","c8c875e929834eb68a41b3f03342d01e","a2c77a52e831469ca31fed12b93f678b","efca18f24e6c4511aa101f0b1cb85984","6c0fd2a80e8f45ce97bd975ca78d52ff","cac5eb1e82fd49778bd7a3935407ca97","39792c304e214754a79ac6149f60235f","5cc20b77c6b545c5be4f8e7ca119fc1b","713f5bcf8d0a46de83f7fe95b26ee371","b8a63b70e7644481b58e0585acee6fc9","97ee03cd7019476ab05f8f3e5409ecc5","47cdaf87f71f4d66a507c6a7a1b192b4","367d10e839c74473bf0ad1a338813bf1","af48f95aeb5846e7a74e084aa3008b5f","eaaf0ba57b8d49fea84e8625b6dc3ecc","1cc5ff1aef054fa1aafe1d0e071a8075","e76c3998f35f4c379f9bcd8db14fba15","359282abf3ba4424ae9bbce9bd480f13","749cbcd61593431cbd7d4088d73e0762","afe8a310755140269afeb03d29e4c2d3","9b0117e2b53646fbb14c28d8270104e1","43ef367b02a747c7b00313120d5228fe","90309ad067b547258caccf4a6eff9bab","5b5de9446bde47afb1c7f203683ecdcd","f6f4f62bef124fd7948e9ff5e44b6c91","48c16fb9270748eca176fbb68a4c80b0","fe3d36ea9d624fae900b5aaf3803bd13","e219200db4924f90851e6090cedd2343","8b729b804b7d47ff8cd1fcb47050da00","36525ecaee7c46be8f5ff42f57b96d4f","1779961ce0d14e87bb64c55863dbb1bc","a60e608ac0ea4c0196ca56f2a5e9c456","a81394ff73a941469e6010872eacd1ae","5b5f1d75503d48d58881e8e701083ed1","aa23ccc95a704231a0309ec021d88c63","ec9837be2aa740b799645982cdc1b64d","f117be183506492caee883ca39d4c025","c25a583a749b4f8788e7c5f1e26b4465","b4c2b2a945654243a661f15d47a9bd5c","1706ee7905344746b302191d10eca2d1","678d0ab64eee47b2ad31cfb688df1787","af0bee339bc2411b95a066b93f39723a"]},"id":"R0L0KNWXhM0d","outputId":"7ce66db5-e446-46e4-d017-697d616610b7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad25fe701fad4c1fad7f91aa34b0543e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8a63b70e7644481b58e0585acee6fc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b0117e2b53646fbb14c28d8270104e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a60e608ac0ea4c0196ca56f2a5e9c456"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","import numpy as np\n","from transformers import BertTokenizer, BertModel\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","\n","# Define the device to use for training\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load the datasets\n","train_data = pd.read_csv(\"/content/drive/MyDrive/NEEWWWWW/DATA_NEW/PC/1000/train_800.csv\")\n","test_data = pd.read_csv(\"/content/drive/MyDrive/NEEWWWWW/DATA_NEW/PC/1000/test_200.csv\")\n","\n","# Define the BERT model and tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n","model = BertModel.from_pretrained('bert-large-cased', output_hidden_states=True)\n","model.to(device)\n","\n","# Define the dataset class\n","class CustomDataset(Dataset):\n","    def __init__(self, df):\n","        self.df = df\n","        self.tokenizer = tokenizer\n","    \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, idx):\n","        text = self.df.iloc[idx]['text']\n","        label = self.df.iloc[idx]['label']\n","        \n","        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n","        input_ids = inputs['input_ids'].squeeze(0)\n","        attention_mask = inputs['attention_mask'].squeeze(0)\n","        \n","        return {'input_ids': input_ids.to(device), 'attention_mask': attention_mask.to(device), 'label': torch.tensor(label).to(device)}\n","\n","# Define the data loaders\n","train_dataset = CustomDataset(train_data)\n","test_dataset = CustomDataset(test_data)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Define the training and testing functions\n","def train(model, train_loader, optimizer, criterion):\n","    model.train()\n","    train_loss = 0\n","    train_acc = 0\n","    total = 0\n","    layer_train_loss_data = []\n","    layer_train_acc_data = []\n","    \n","    for batch in train_loader:\n","        input_ids = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        labels = batch['label']\n","        \n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        logits = outputs.last_hidden_state[:, 0, :]\n","        loss = criterion(logits, labels)\n","        \n","        loss.backward()\n","        optimizer.step()\n","        \n","        train_loss += loss.item() * len(input_ids)\n","        train_acc += accuracy_score(labels.cpu().numpy(), np.argmax(logits.cpu().detach().numpy(), axis=1)) * len(input_ids)\n","        total += len(input_ids)\n","        \n","        for i in range(24):\n","            # Calculate the loss and accuracy for this layer\n","            layer_logits = outputs.hidden_states[i][:, 0, :]\n","            layer_loss = criterion(layer_logits, labels)\n","            layer_preds = np.argmax(layer_logits.cpu().detach().numpy(), axis=1)\n","            layer_labels = labels.cpu().numpy()\n","            layer_acc = accuracy_score(layer_labels, layer_preds)\n","            layer_train_loss_data.append(layer_loss.item())\n","            layer_train_acc_data.append(layer_acc)\n","\n","    # Calculate the average loss and accuracy for each layer\n","    layer_train_loss = [np.mean(layer_train_loss_data[i::24]) for i in range(24)]\n","    layer_train_acc = [np.mean(layer_train_acc_data[i::24]) for i in range(24)]\n","    \n","    # Calculate the overall train loss and accuracy\n","    overall_train_loss = train_loss / total\n","    overall_train_acc = train_acc / total\n","    \n","    return overall_train_loss, overall_train_acc, layer_train_loss, layer_train_acc\n","\n","\n","def test(model, test_loader, criterion):\n","    model.eval()\n","    test_loss = 0\n","    test_acc = 0\n","    total = 0\n","    hidden_states = [[] for _ in range(24)]\n","    layer_test_loss_data = []\n","    layer_test_acc_data = []\n","    \n","    with torch.no_grad():\n","        for batch in test_loader:\n","            input_ids = batch['input_ids']\n","            attention_mask = batch['attention_mask']\n","            labels = batch['label']\n","            \n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            logits = outputs.last_hidden_state[:, 0, :]\n","            loss = criterion(logits, labels)\n","            \n","            test_loss += loss.item() * len(input_ids)\n","            test_acc += accuracy_score(labels.cpu().numpy(), np.argmax(logits.cpu().detach().numpy(), axis=1)) * len(input_ids)\n","            total += len(input_ids)\n","            \n","            for i in range(24):\n","                hidden_states[i].append(outputs.hidden_states[i].cpu().detach().numpy())\n","                \n","                # Calculate the loss and accuracy for this layer\n","                layer_logits = outputs.hidden_states[i][:, 0, :]\n","                layer_loss = criterion(layer_logits, labels)\n","                layer_preds = np.argmax(layer_logits.cpu().detach().numpy(), axis=1)\n","                layer_labels = labels.cpu().numpy()\n","                layer_acc = accuracy_score(layer_labels, layer_preds)\n","                layer_test_loss_data.append(layer_loss.item())\n","                layer_test_acc_data.append(layer_acc)\n","\n","    # Calculate the average loss and accuracy for each layer\n","    layer_test_loss = [np.mean(layer_test_loss_data[i::24]) for i in range(24)]\n","    layer_test_acc = [np.mean(layer_test_acc_data[i::24]) for i in range(24)]\n","        \n","    # Calculate the overall test loss and accuracy\n","    overall_test_loss = test_loss / total\n","    overall_test_acc = test_acc / total\n","    \n","    return overall_test_loss, overall_test_acc, layer_test_loss, layer_test_acc, hidden_states\n","\n","# Define the optimizer and loss function\n","optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# Train the model for 10 epochs\n","epochs = 10\n","train_losses = []\n","train_accs = []\n","test_losses = []\n","test_accs = []\n","layer_train_losses = [[] for _ in range(24)]\n","layer_train_accs = [[] for _ in range(24)]\n","layer_test_losses = [[] for _ in range(24)]\n","layer_test_accs = [[] for _ in range(24)]\n","for epoch in range(epochs):\n","    train_loss, train_acc, layer_train_loss, layer_train_acc = train(model, train_loader, optimizer, criterion)\n","    train_losses.append(train_loss)\n","    train_accs.append(train_acc)\n","    for i in range(24):\n","        layer_train_losses[i].append(layer_train_loss[i])\n","        layer_train_accs[i].append(layer_train_acc[i])\n","    \n","    test_loss, test_acc, layer_test_loss, layer_test_acc, hidden_states = test(model, test_loader, criterion)\n","    test_losses.append(test_loss)\n","    test_accs.append(test_acc)\n","    for i in range(24):\n","        layer_test_losses[i].append(layer_test_loss[i])\n","        layer_test_accs[i].append(layer_test_acc[i])\n","    \n","    print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc*100:.4f}\")\n","    print(f\"Epoch {epoch+1} - Test Loss: {test_loss:.4f} - Test Acc: {test_acc*100:.4f}\")\n","\n"],"metadata":{"id":"NxrLUho4aMVE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the results\n","fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n","axs[0, 0].plot(train_losses, label='Train Loss')\n","axs[0, 0].plot(test_losses, label='Test Loss')\n","axs[0, 0].set_xlabel('Epochs', fontsize=14)\n","axs[0, 0].set_ylabel('Loss', fontsize=14)\n","axs[0, 0].set_title('Overall Loss', fontsize=16)\n","axs[0, 0].legend(fontsize=12)\n","\n","axs[0, 1].plot(train_accs, label='Train Acc')\n","axs[0, 1].plot(test_accs, label='Test Acc')\n","axs[0, 1].set_xlabel('Epochs', fontsize=14)\n","axs[0, 1].set_ylabel('Accuracy', fontsize=14)\n","axs[0, 1].set_title('Overall Accuracy', fontsize=16)\n","axs[0, 1].legend(fontsize=12)\n","\n","for i in range(12):\n","    axs[1, 0].plot(layer_train_losses[i], label=f'Layer {i+1} Train Loss')\n","    axs[1, 0].plot(layer_test_losses[i], label=f'Layer {i+1} Test Loss')\n","    axs[1, 0].set_xlabel('Epochs', fontsize=14)\n","    axs[1, 0].set_ylabel('Loss', fontsize=14)\n","    axs[1, 0].set_title('Layer Loss', fontsize=16)\n","    axs[1, 0].legend(fontsize=12)\n","\n","    axs[1, 1].plot(layer_train_accs[i], label=f'Layer {i+1} Train Acc')\n","    axs[1, 1].plot(layer_test_accs[i], label=f'Layer {i+1} Test Acc')\n","    axs[1, 1].set_xlabel('Epochs', fontsize=14)\n","    axs[1, 1].set_ylabel('Accuracy', fontsize=14)\n","    axs[1, 1].set_title('Layer Accuracy', fontsize=16)\n","    axs[1, 1].legend(fontsize=12)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"_vQZXeyHcSTe"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyPlVxJftKfBvFW+9eQiQuMu"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ad25fe701fad4c1fad7f91aa34b0543e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_64bbb86a1c1b44a3aaeb523975b52734","IPY_MODEL_4e4afd134a554c17af6262ad48d45660","IPY_MODEL_c8c875e929834eb68a41b3f03342d01e"],"layout":"IPY_MODEL_a2c77a52e831469ca31fed12b93f678b"}},"64bbb86a1c1b44a3aaeb523975b52734":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efca18f24e6c4511aa101f0b1cb85984","placeholder":"​","style":"IPY_MODEL_6c0fd2a80e8f45ce97bd975ca78d52ff","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"4e4afd134a554c17af6262ad48d45660":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cac5eb1e82fd49778bd7a3935407ca97","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39792c304e214754a79ac6149f60235f","value":213450}},"c8c875e929834eb68a41b3f03342d01e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cc20b77c6b545c5be4f8e7ca119fc1b","placeholder":"​","style":"IPY_MODEL_713f5bcf8d0a46de83f7fe95b26ee371","value":" 213k/213k [00:00&lt;00:00, 1.88MB/s]"}},"a2c77a52e831469ca31fed12b93f678b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efca18f24e6c4511aa101f0b1cb85984":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c0fd2a80e8f45ce97bd975ca78d52ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cac5eb1e82fd49778bd7a3935407ca97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39792c304e214754a79ac6149f60235f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5cc20b77c6b545c5be4f8e7ca119fc1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"713f5bcf8d0a46de83f7fe95b26ee371":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8a63b70e7644481b58e0585acee6fc9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_97ee03cd7019476ab05f8f3e5409ecc5","IPY_MODEL_47cdaf87f71f4d66a507c6a7a1b192b4","IPY_MODEL_367d10e839c74473bf0ad1a338813bf1"],"layout":"IPY_MODEL_af48f95aeb5846e7a74e084aa3008b5f"}},"97ee03cd7019476ab05f8f3e5409ecc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaaf0ba57b8d49fea84e8625b6dc3ecc","placeholder":"​","style":"IPY_MODEL_1cc5ff1aef054fa1aafe1d0e071a8075","value":"Downloading (…)okenizer_config.json: 100%"}},"47cdaf87f71f4d66a507c6a7a1b192b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e76c3998f35f4c379f9bcd8db14fba15","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_359282abf3ba4424ae9bbce9bd480f13","value":29}},"367d10e839c74473bf0ad1a338813bf1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_749cbcd61593431cbd7d4088d73e0762","placeholder":"​","style":"IPY_MODEL_afe8a310755140269afeb03d29e4c2d3","value":" 29.0/29.0 [00:00&lt;00:00, 635B/s]"}},"af48f95aeb5846e7a74e084aa3008b5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaaf0ba57b8d49fea84e8625b6dc3ecc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cc5ff1aef054fa1aafe1d0e071a8075":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e76c3998f35f4c379f9bcd8db14fba15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"359282abf3ba4424ae9bbce9bd480f13":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"749cbcd61593431cbd7d4088d73e0762":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afe8a310755140269afeb03d29e4c2d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b0117e2b53646fbb14c28d8270104e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43ef367b02a747c7b00313120d5228fe","IPY_MODEL_90309ad067b547258caccf4a6eff9bab","IPY_MODEL_5b5de9446bde47afb1c7f203683ecdcd"],"layout":"IPY_MODEL_f6f4f62bef124fd7948e9ff5e44b6c91"}},"43ef367b02a747c7b00313120d5228fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48c16fb9270748eca176fbb68a4c80b0","placeholder":"​","style":"IPY_MODEL_fe3d36ea9d624fae900b5aaf3803bd13","value":"Downloading (…)lve/main/config.json: 100%"}},"90309ad067b547258caccf4a6eff9bab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e219200db4924f90851e6090cedd2343","max":762,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b729b804b7d47ff8cd1fcb47050da00","value":762}},"5b5de9446bde47afb1c7f203683ecdcd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36525ecaee7c46be8f5ff42f57b96d4f","placeholder":"​","style":"IPY_MODEL_1779961ce0d14e87bb64c55863dbb1bc","value":" 762/762 [00:00&lt;00:00, 20.9kB/s]"}},"f6f4f62bef124fd7948e9ff5e44b6c91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48c16fb9270748eca176fbb68a4c80b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe3d36ea9d624fae900b5aaf3803bd13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e219200db4924f90851e6090cedd2343":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b729b804b7d47ff8cd1fcb47050da00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36525ecaee7c46be8f5ff42f57b96d4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1779961ce0d14e87bb64c55863dbb1bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a60e608ac0ea4c0196ca56f2a5e9c456":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a81394ff73a941469e6010872eacd1ae","IPY_MODEL_5b5f1d75503d48d58881e8e701083ed1","IPY_MODEL_aa23ccc95a704231a0309ec021d88c63"],"layout":"IPY_MODEL_ec9837be2aa740b799645982cdc1b64d"}},"a81394ff73a941469e6010872eacd1ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f117be183506492caee883ca39d4c025","placeholder":"​","style":"IPY_MODEL_c25a583a749b4f8788e7c5f1e26b4465","value":"Downloading pytorch_model.bin: 100%"}},"5b5f1d75503d48d58881e8e701083ed1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4c2b2a945654243a661f15d47a9bd5c","max":1338740706,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1706ee7905344746b302191d10eca2d1","value":1338740706}},"aa23ccc95a704231a0309ec021d88c63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_678d0ab64eee47b2ad31cfb688df1787","placeholder":"​","style":"IPY_MODEL_af0bee339bc2411b95a066b93f39723a","value":" 1.34G/1.34G [00:29&lt;00:00, 47.8MB/s]"}},"ec9837be2aa740b799645982cdc1b64d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f117be183506492caee883ca39d4c025":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c25a583a749b4f8788e7c5f1e26b4465":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4c2b2a945654243a661f15d47a9bd5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1706ee7905344746b302191d10eca2d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"678d0ab64eee47b2ad31cfb688df1787":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af0bee339bc2411b95a066b93f39723a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}