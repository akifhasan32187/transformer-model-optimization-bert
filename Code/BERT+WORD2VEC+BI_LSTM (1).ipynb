{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":101,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XrbKsdYmRB86","outputId":"662d4d86-856b-40fc-b3c7-ae1c5f3b271e","executionInfo":{"status":"ok","timestamp":1684949688843,"user_tz":-360,"elapsed":4700,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)\n","import string\n","import re\n","import nltk\n","from os import listdir\n","from collections import Counter\n","from numpy import array\n","import numpy as np\n","import pandas as pd\n","from nltk.corpus import stopwords"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3FAexYTaeOs","outputId":"ea421313-2d91-42d1-a644-e7bde7052523","executionInfo":{"status":"ok","timestamp":1684949688844,"user_tz":-360,"elapsed":11,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["2.12.0\n"]}]},{"cell_type":"code","source":["# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"YX2iCeyxSmGY","executionInfo":{"status":"ok","timestamp":1684949688844,"user_tz":-360,"elapsed":5,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade tensorflow-gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnO_SNnvaXKs","outputId":"053560f4-5924-4236-ce60-cfd5c99fa782","executionInfo":{"status":"ok","timestamp":1684949692538,"user_tz":-360,"elapsed":3699,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-gpu\n","  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n"]}]},{"cell_type":"code","source":["nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JE3JnewZal3V","outputId":"521cc6b1-b8e8-4f05-b321-f3c69592fcb5","executionInfo":{"status":"ok","timestamp":1684949692540,"user_tz":-360,"elapsed":57,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":105,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":105}]},{"cell_type":"code","source":["# turn a doc into clean tokens\n","def clean_doc(doc):\n","# split into tokens by white space\n","    tokens = doc.split()\n","# prepare regex for char filtering\n","    re_punc = re.compile( ' [%s] ' % re.escape(string.punctuation))\n","# remove punctuation from each word\n","    tokens = [re_punc.sub( '' , w) for w in tokens]\n","# remove remaining tokens that are not alphabetic\n","    tokens = [word for word in tokens if word.isalpha()]\n","# filter out stop words\n","    stop_words = set(stopwords.words( 'english' ))\n","    tokens = [w for w in tokens if not w in stop_words]\n","# filter out short tokens\n","    tokens = [word for word in tokens if len(word) > 1]\n","    return tokens\n"],"metadata":{"id":"rVZQ-gwvau9c","executionInfo":{"status":"ok","timestamp":1684949692542,"user_tz":-360,"elapsed":56,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["# Load the dataset\n","train_df = pd.read_csv(\"/content/drive/MyDrive/NEEWWWWW/DATA_NEW/PC/500/train_400.csv\")\n","test_df = pd.read_csv(\"/content/drive/MyDrive/NEEWWWWW/DATA_NEW/PC/500/test_100.csv\")\n"],"metadata":{"id":"KED1Amj0SogI","executionInfo":{"status":"ok","timestamp":1684949692543,"user_tz":-360,"elapsed":56,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":107,"outputs":[]},{"cell_type":"code","source":["train_df[['text','label']].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"tcApnTCZa67d","outputId":"80687b69-a5e1-4bc5-9055-21c29253bae2","executionInfo":{"status":"ok","timestamp":1684949692544,"user_tz":-360,"elapsed":57,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":108,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text  label\n","0                           Easy to use, economical!      1\n","1          Digital is where it's at...down with d...      1\n","2          Good image quality, 3x optical zoom, m...      1\n","3          Awesome features/easy to use/fun/versa...      1\n","4                                      simple to use      1"],"text/html":["\n","  <div id=\"df-0fee19e7-2070-4df5-8966-ee099b200463\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Easy to use, economical!</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Digital is where it's at...down with d...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Good image quality, 3x optical zoom, m...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Awesome features/easy to use/fun/versa...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>simple to use</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fee19e7-2070-4df5-8966-ee099b200463')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0fee19e7-2070-4df5-8966-ee099b200463 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0fee19e7-2070-4df5-8966-ee099b200463');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":108}]},{"cell_type":"code","source":["train_df['label'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADV0B36pbDRM","outputId":"9c80c157-58d5-4116-cbef-572974e9db55","executionInfo":{"status":"ok","timestamp":1684949692545,"user_tz":-360,"elapsed":57,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":109,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    200\n","0    200\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":109}]},{"cell_type":"code","source":["train_pos_sentences = train_df['text'].loc[train_df.label==1]\n","train_neg_sentences = train_df['text'].loc[train_df.label==0]\n","train_pos_sentences = train_pos_sentences.reset_index(drop=True)\n","train_neg_sentences = train_neg_sentences.reset_index(drop=True)\n","\n","test_pos_sentences = test_df['text'].loc[test_df.label==1]\n","test_neg_sentences = test_df['text'].loc[test_df.label==0]\n","test_pos_sentences = test_pos_sentences.reset_index(drop=True)\n","test_neg_sentences = test_neg_sentences.reset_index(drop=True)"],"metadata":{"id":"NGihMqIgbGmV","executionInfo":{"status":"ok","timestamp":1684949692545,"user_tz":-360,"elapsed":53,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["print(train_pos_sentences[0:5].values)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gqqnlCzLbe1k","outputId":"477737eb-dec5-4dc5-d17e-0c9fed021776","executionInfo":{"status":"ok","timestamp":1684949692545,"user_tz":-360,"elapsed":52,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["['        Easy to use, economical!'\n"," \"        Digital is where it's at...down with developing film!\"\n"," '        Good image quality, 3x optical zoom, macro mode, inexpensive'\n"," '        Awesome features/easy to use/fun/versatile/low price/Cust SVS 2nd 2 none!'\n"," '        simple to use']\n"]}]},{"cell_type":"code","source":["print(train_neg_sentences[0:5].values)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x_d4nW_rbpYd","outputId":"5af7a7ce-f186-4bc4-8d15-6d7431a9281f","executionInfo":{"status":"ok","timestamp":1684949692545,"user_tz":-360,"elapsed":50,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["['        LCD hard to see in the sun, LCD freezes'\n"," '        Eats batteries, plan on shelling out more money, Not very high res'\n"," '        Very Poor customer service.'\n"," '        The camera I have can only be connected to your computer via a serial port, and as I have a serial mouse and a serial modem, I have no spare ports while online, forcing me to disconnect to upload new pictures. :-( [Update: I now have a PS/2 mouse and can p'\n"," '        Potentially weak LCD screen']\n"]}]},{"cell_type":"code","source":["text = train_pos_sentences[0]\n","tokens = clean_doc(text)\n","print(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1VAhFCtKbrR0","outputId":"d3c0c9b5-07a0-4046-ccd3-5f92b60677cc","executionInfo":{"status":"ok","timestamp":1684949692546,"user_tz":-360,"elapsed":48,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["['Easy']\n"]}]},{"cell_type":"code","source":["# load doc and add to vocab\n","def add_sent_to_vocab(text,vocab):\n","# clean text\n","    tokens = clean_doc(text)\n","# update counts\n","    vocab.update(tokens)\n","\n","def process_docs_to_vocab(sentList, vocab):\n","    for i in range(len(sentList)):\n","        text = sentList[i]\n","        add_sent_to_vocab(text,vocab)\n","       \n","# turn a doc into clean tokens\n","def clean_doc_wVocab(doc, vocab):\n","\t# split into tokens by white space\n","\ttokens = doc.split()\n","\t# prepare regex for char filtering\n","\tre_punc = re.compile('[%s]' % re.escape(string.punctuation))\n","\t# remove punctuation from each word\n","\ttokens = [re_punc.sub('', w) for w in tokens]\n","\t# filter out tokens not in vocab\n","\ttokens = [w for w in tokens if w in vocab]\n","\ttokens = ' '.join(tokens)\n","\treturn tokens\n","\n","# load all docs in a directory, into tokens\n","def process_docs_to_tokens(sentList, vocab):\n","\tdocuments = list()\n","\t# walk through all sentences\n","\tfor i in range(len(sentList)):\n","\t\tdoc = sentList[i]\n","\t\t# clean doc\n","\t\ttokens = clean_doc_wVocab(doc, vocab)\n","\t\t# add to list\n","\t\tdocuments.append(tokens)\n","\treturn documents\n","\n","# integer encode and pad documents\n","def encode_docs(tokenizer, max_length, docs):\n","    # integer encode\n","    encoded = tokenizer.texts_to_sequences(docs)\n","    # pad sequences\n","    padded = tf.keras.preprocessing.sequence.pad_sequences(encoded, maxlen=max_length, padding='post')\n","    return padded\n","\n","# fit a tokenizer\n","def create_tokenizer(lines):\n","\ttokenizer = tf.keras.preprocessing.text.Tokenizer()\n","\ttokenizer.fit_on_texts(lines)\n","\treturn tokenizer"],"metadata":{"id":"iEWCtiZ3bxx9","executionInfo":{"status":"ok","timestamp":1684949692546,"user_tz":-360,"elapsed":46,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":114,"outputs":[]},{"cell_type":"code","source":["# define vocab\n","vocab = Counter()\n","# add all docs to vocab\n","process_docs_to_vocab(train_df['text'], vocab)\n","process_docs_to_vocab(test_df['text'], vocab)\n","print(len(vocab))\n","# print the top words in the vocab\n","print(vocab.most_common(50))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1L1Am2Tb1VE","outputId":"d62c5471-cd68-4bfd-e043-28f46f2f8e34","executionInfo":{"status":"ok","timestamp":1684949692546,"user_tz":-360,"elapsed":46,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":115,"outputs":[{"output_type":"stream","name":"stdout","text":["813\n","[('quality', 61), ('good', 48), ('easy', 40), ('use', 32), ('Easy', 30), ('great', 28), ('low', 22), ('Good', 20), ('image', 20), ('camera', 19), ('battery', 19), ('pictures', 18), ('picture', 18), ('No', 18), ('Great', 17), ('software', 16), ('poor', 16), ('flash', 14), ('LCD', 13), ('USB', 13), ('high', 12), ('small', 12), ('batteries', 12), ('price', 11), ('print', 11), ('Poor', 11), ('bad', 11), ('inexpensive', 10), ('get', 10), ('hard', 10), ('cheap', 9), ('resolution', 9), ('Low', 9), ('lot', 9), ('Not', 9), ('simple', 8), ('fast', 8), ('digital', 8), ('Battery', 8), ('Picture', 7), ('customer', 7), ('Very', 7), ('Excellent', 7), ('photo', 7), ('memory', 7), ('Ease', 6), ('You', 6), ('features', 6), ('enough', 6), ('takes', 6)]\n"]}]},{"cell_type":"code","source":["# load and clean a dataset\n","def load_clean_dataset(vocab):\n","\t# load documents\n","\tneg = process_docs_to_tokens(train_neg_sentences, vocab)\n","\tpos = process_docs_to_tokens(train_pos_sentences, vocab)\n","\tdocs = neg + pos\n","\t# prepare labels\n","\tlabels = array([0 for _ in range(len(neg))] + [1 for _ in range(len(pos))])\n","\treturn docs, labels\n","\n","# load and clean a dataset\n","def load_clean_dataset_test(vocab):\n","\t# load documents\n","\tneg = process_docs_to_tokens(test_neg_sentences, vocab)\n","\tpos = process_docs_to_tokens(test_pos_sentences, vocab)\n","\tdocs = neg + pos\n","\t# prepare labels\n","\tlabels = array([0 for _ in range(len(neg))] + [1 for _ in range(len(pos))])\n","\treturn docs, labels"],"metadata":{"id":"MyGSm_Dsb5oF","executionInfo":{"status":"ok","timestamp":1684949692547,"user_tz":-360,"elapsed":44,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":116,"outputs":[]},{"cell_type":"code","source":["# load training data\n","train_docs, ytrain = load_clean_dataset(vocab)\n","# create the tokenizer\n","tokenizer = create_tokenizer(train_docs)\n","# define vocabulary size\n","vocab_size = len(tokenizer.word_index) + 1\n","print('Vocabulary size: %d' % vocab_size)\n","# calculate the maximum sequence length\n","max_length = max([len(s.split()) for s in train_docs])\n","print('Maximum length: %d' % max_length)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APszFmKbb8-8","outputId":"ff8c0ffd-d674-4fa1-a0e2-6b8f61833047","executionInfo":{"status":"ok","timestamp":1684949692547,"user_tz":-360,"elapsed":44,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":117,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 619\n","Maximum length: 17\n"]}]},{"cell_type":"code","source":["print(train_df['text'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HOdgrNHhcETs","outputId":"d205051d-688b-4f9e-8545-c88969c5219e","executionInfo":{"status":"ok","timestamp":1684949692547,"user_tz":-360,"elapsed":41,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":118,"outputs":[{"output_type":"stream","name":"stdout","text":["        Easy to use, economical!\n"]}]},{"cell_type":"code","source":["train_docs[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"8Hzai_4UcI9U","outputId":"5da0c10a-3468-41e4-b6cc-ce5b40cfefa9","executionInfo":{"status":"ok","timestamp":1684949692547,"user_tz":-360,"elapsed":39,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":119,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'LCD hard see LCD freezes'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":119}]},{"cell_type":"code","source":["Xtrain = encode_docs(tokenizer, max_length, train_docs)"],"metadata":{"id":"8bYr8INHcLJt","executionInfo":{"status":"ok","timestamp":1684949692548,"user_tz":-360,"elapsed":39,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":120,"outputs":[]},{"cell_type":"code","source":["print(Xtrain.shape)\n","print(Xtrain[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHhXY3LicVri","outputId":"520d6605-a32c-4bfb-a522-f8077a3eac89","executionInfo":{"status":"ok","timestamp":1684949692548,"user_tz":-360,"elapsed":39,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["(400, 17)\n","[ 22  26  95  22 266   0   0   0   0   0   0   0   0   0   0   0   0]\n"]}]},{"cell_type":"code","source":["t = tokenizer\n","print(t.word_counts)\n","#print(t.document_count)\n","#print(t.word_index)\n","#print(t.word_docs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6i0wKc5cXwR","outputId":"08ac53e1-28b9-4051-d6a6-29def44d1759","executionInfo":{"status":"ok","timestamp":1684949692548,"user_tz":-360,"elapsed":37,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":122,"outputs":[{"output_type":"stream","name":"stdout","text":["OrderedDict([('lcd', 15), ('hard', 13), ('see', 4), ('freezes', 1), ('eats', 5), ('batteries', 12), ('plan', 3), ('shelling', 1), ('money', 6), ('not', 8), ('high', 16), ('res', 1), ('very', 6), ('poor', 28), ('customer', 5), ('service', 6), ('the', 4), ('camera', 21), ('connected', 1), ('computer', 3), ('via', 1), ('serial', 5), ('mouse', 2), ('spare', 1), ('ports', 1), ('forcing', 1), ('disconnect', 1), ('upload', 1), ('new', 1), ('pictures', 31), ('potentially', 1), ('weak', 2), ('screen', 4), ('slightly', 2), ('dated', 1), ('technology', 1), ('no', 12), ('flash', 32), ('rechargeable', 1), ('must', 2), ('battery', 20), ('life', 6), ('limited', 3), ('use', 52), ('mac', 3), ('compatability', 1), ('go', 2), ('dead', 2), ('short', 5), ('time', 7), ('consumption', 1), ('uses', 2), ('lot', 7), ('optical', 4), ('zoom', 3), ('bulky', 4), ('odd', 1), ('shutter', 2), ('slow', 3), ('low', 30), ('does', 2), ('meet', 1), ('advertised', 1), ('tiny', 5), ('button', 2), ('people', 1), ('large', 6), ('hands', 1), ('difficulty', 1), ('downloading', 1), ('hog', 1), ('miserable', 1), ('cover', 3), ('lock', 1), ('integrity', 1), ('latency', 1), ('pics', 5), ('size', 11), ('construction', 3), ('flaws', 2), ('continuous', 1), ('lens', 2), ('long', 4), ('photowise', 2), ('lacks', 1), ('features', 8), ('earlier', 1), ('scan', 1), ('rate', 1), ('usb', 14), ('connection', 2), ('work', 7), ('usability', 1), ('design', 7), ('needs', 5), ('retain', 1), ('settings', 2), ('may', 5), ('compatible', 2), ('think', 2), ('except', 1), ('digital', 10), ('cameras', 1), ('quality', 99), ('image', 22), ('picture', 22), ('interface', 4), ('resolution', 16), ('quirky', 2), ('file', 1), ('transfer', 2), ('grainy', 3), ('images', 7), ('extremely', 6), ('bad', 12), ('kind', 1), ('feel', 1), ('person', 1), ('bought', 1), ('taken', 2), ('market', 1), ('lack', 2), ('you', 6), ('get', 7), ('paid', 2), ('horrible', 2), ('pathetic', 1), ('list', 1), ('goes', 1), ('clarity', 1), ('adapter', 2), ('usage', 2), ('everything', 6), ('feels', 2), ('junky', 1), ('substandard', 1), ('confusing', 1), ('software', 21), ('dont', 3), ('like', 4), ('upgradable', 1), ('shaky', 1), ('stupid', 3), ('buy', 3), ('beg', 1), ('produce', 1), ('decent', 5), ('photos', 15), ('without', 2), ('incredible', 1), ('effort', 1), ('expensive', 7), ('piece', 3), ('junk', 1), ('taking', 4), ('important', 1), ('still', 5), ('good', 59), ('deal', 1), ('power', 2), ('included', 6), ('poorly', 1), ('made', 2), ('view', 2), ('unacceptable', 2), ('performance', 2), ('drainage', 1), ('issue', 1), ('warranty', 1), ('problems', 6), ('utterly', 1), ('awful', 1), ('fact', 1), ('exists', 1), ('every', 2), ('photo', 11), ('end', 2), ('say', 1), ('nothing', 1), ('badly', 1), ('constructed', 1), ('lots', 5), ('light', 15), ('gobbles', 1), ('looks', 1), ('toylike', 1), ('memory', 8), ('enough', 6), ('ugly', 1), ('display', 2), ('mp', 3), ('base', 1), ('graphic', 1), ('annoying', 1), ('beep', 4), ('buttons', 1), ('uncomfortable', 1), ('spot', 1), ('drains', 2), ('cheap', 33), ('plastic', 2), ('it', 5), ('likes', 1), ('allow', 3), ('conversion', 2), ('bitmap', 1), ('jpeg', 1), ('takes', 6), ('getting', 2), ('used', 3), ('small', 28), ('some', 2), ('trouble', 1), ('installing', 1), ('due', 2), ('missing', 2), ('webcam', 6), ('support', 5), ('beeping', 1), ('noise', 1), ('marginal', 4), ('why', 1), ('would', 1), ('spy', 1), ('flimsy', 3), ('lighting', 4), ('break', 1), ('irritating', 1), ('ok', 1), ('few', 1), ('situations', 1), ('lose', 1), ('pix', 1), ('goez', 1), ('works', 4), ('windows', 1), ('best', 3), ('available', 2), ('storage', 7), ('inadequate', 1), ('product', 1), ('endless', 1), ('cons', 2), ('clip', 2), ('stay', 1), ('hooked', 1), ('ever', 1), ('worth', 2), ('take', 4), ('need', 2), ('one', 6), ('plain', 1), ('paper', 6), ('ease', 7), ('changing', 1), ('cartridges', 7), ('noisy', 5), ('ink', 12), ('probably', 1), ('loud', 7), ('clean', 1), ('print', 12), ('head', 1), ('occasionally', 1), ('big', 6), ('moments', 1), ('change', 1), ('cleaned', 1), ('real', 1), ('color', 4), ('lousy', 1), ('never', 1), ('find', 5), ('replacement', 2), ('as', 2), ('running', 1), ('costs', 3), ('somewhat', 3), ('come', 1), ('mind', 1), ('around', 3), ('constant', 1), ('maintenance', 2), ('blurred', 1), ('price', 17), ('less', 2), ('printer', 6), ('misfeed', 1), ('macintosh', 1), ('localtalk', 1), ('optional', 1), ('information', 1), ('electronic', 1), ('version', 1), ('manual', 2), ('black', 5), ('text', 4), ('bit', 1), ('shakes', 1), ('printing', 7), ('shake', 1), ('rendition', 2), ('opinion', 1), ('pretty', 5), ('bigger', 1), ('warm', 2), ('page', 3), ('priced', 3), ('great', 33), ('stiff', 1), ('outdoor', 3), ('pay', 3), ('pic', 2), ('hold', 2), ('many', 2), ('resoultion', 1), ('drivers', 1), ('xp', 1), ('fast', 20), ('removed', 1), ('where', 1), ('removable', 2), ('ya', 1), ('vague', 1), ('arent', 1), ('much', 4), ('even', 2), ('your', 1), ('found', 2), ('better', 2), ('stuff', 1), ('cracker', 1), ('jack', 1), ('boxes', 1), ('understand', 1), ('makes', 2), ('necessary', 1), ('mine', 1), ('vivitar', 1), ('brand', 1), ('name', 2), ('puny', 1), ('internal', 2), ('powering', 1), ('operate', 2), ('properly', 1), ('little', 2), ('built', 3), ('range', 3), ('cf', 2), ('doors', 1), ('preview', 3), ('broken', 1), ('none', 3), ('yet', 2), ('fold', 1), ('almost', 1), ('everyday', 1), ('its', 1), ('manipulate', 1), ('crowds', 1), ('wear', 1), ('well', 7), ('basket', 4), ('reach', 3), ('car', 1), ('seat', 1), ('attached', 1), ('baby', 1), ('trend', 1), ('difficult', 4), ('phone', 1), ('handle', 2), ('height', 1), ('adjustment', 1), ('pushing', 1), ('explorer', 1), ('keep', 1), ('my', 1), ('toddler', 1), ('standing', 1), ('too', 2), ('heavy', 6), ('cup', 1), ('push', 2), ('turn', 1), ('when', 1), ('using', 1), ('infant', 1), ('older', 4), ('child', 7), ('cannot', 1), ('manuvering', 1), ('stores', 1), ('fairly', 2), ('access', 1), ('room', 2), ('taller', 1), ('weight', 3), ('manuver', 1), ('distance', 1), ('catapulting', 1), ('occupant', 1), ('brakes', 1), ('outgrow', 1), ('maneuver', 1), ('folding', 1), ('normal', 1), ('harness', 1), ('system', 1), ('toner', 1), ('cartridge', 1), ('network', 1), ('environments', 1), ('envelopes', 1), ('graphics', 2), ('clearing', 1), ('jams', 1), ('requires', 1), ('significant', 1), ('component', 1), ('density', 1), ('prints', 6), ('can', 3), ('load', 1), ('loader', 1), ('unreliable', 1), ('easy', 51), ('developing', 1), ('film', 1), ('macro', 2), ('inexpensive', 25), ('awesome', 1), ('svs', 1), ('simple', 8), ('user', 1), ('right', 2), ('compact', 7), ('anybody', 1), ('could', 1), ('reliable', 2), ('funky', 1), ('blue', 1), ('cost', 6), ('fine', 1), ('ebay', 2), ('clear', 2), ('crisp', 2), ('affordable', 6), ('several', 1), ('nice', 6), ('wonderful', 2), ('viewing', 1), ('capacity', 2), ('storing', 1), ('relatively', 2), ('cool', 1), ('looking', 2), ('self', 1), ('look', 2), ('tv', 2), ('carry', 3), ('snapshots', 2), ('pockatable', 1), ('video', 3), ('conferencing', 1), ('photography', 1), ('supposed', 1), ('ability', 3), ('cable', 1), ('extras', 1), ('value', 3), ('web', 4), ('holds', 1), ('card', 1), ('anything', 2), ('beginner', 1), ('agfanet', 1), ('versatility', 1), ('conditions', 1), ('navigation', 1), ('megapixel', 2), ('cord', 1), ('started', 2), ('amateur', 1), ('photographer', 1), ('cheaper', 3), ('excellent', 7), ('connectivity', 1), ('feature', 2), ('mass', 1), ('switchable', 2), ('viewfinder', 1), ('came', 1), ('needed', 1), ('expanded', 1), ('space', 2), ('functional', 1), ('television', 1), ('uncomplicated', 1), ('portable', 4), ('tool', 1), ('students', 1), ('superb', 1), ('true', 1), ('super', 1), ('fun', 5), ('surprisingly', 1), ('email', 1), ('videos', 2), ('conference', 1), ('calling', 1), ('over', 1), ('perfectly', 1), ('camcorder', 1), ('fits', 1), ('independent', 1), ('adequate', 1), ('highly', 1), ('runs', 2), ('aaa', 1), ('kitschy', 1), ('magic', 1), ('bundled', 1), ('three', 1), ('functions', 1), ('variety', 2), ('convinent', 1), ('live', 1), ('imagez', 1), ('picturez', 1), ('movie', 1), ('output', 3), ('reliability', 1), ('set', 1), ('beautiful', 3), ('setup', 4), ('speed', 3), ('consumable', 1), ('economy', 1), ('pc', 1), ('results', 1), ('customizable', 1), ('tone', 1), ('company', 1), ('trust', 1), ('east', 1), ('business', 2), ('terrific', 1), ('faster', 1), ('hp', 2), ('hook', 1), ('install', 3), ('durability', 1), ('ethernet', 1), ('there', 1), ('package', 2), ('editing', 1), ('starter', 1), ('comes', 1), ('worked', 1), ('wanted', 1), ('kids', 1), ('folds', 1), ('lets', 1), ('son', 1), ('point', 1), ('children', 1), ('way', 2), ('walks', 1), ('thinks', 1), ('stroller', 1), ('and', 1), ('keeps', 1), ('four', 1), ('separate', 1), ('all', 1), ('aftermarket', 1), ('fax', 3), ('initially', 1), ('multifunction', 2), ('replaced', 1), ('allows', 1), ('printout', 1), ('mfc', 2), ('laser', 3), ('brother', 1), ('capability', 1), ('lowest', 1), ('per', 3), ('automatic', 1), ('sheet', 1), ('scanner', 2), ('parallel', 1), ('moderately', 1), ('multifunctionality', 1), ('functionality', 1), ('key', 1), ('just', 1), ('fair', 1), ('flatbed', 1), ('designed', 1), ('quick', 2), ('usually', 1), ('mention', 1), ('last', 1), ('quite', 1), ('for', 1), ('okay', 1), ('refills', 1), ('pages', 1), ('minute', 1), ('turns', 1), ('beat', 1), ('supports', 1), ('wide', 1), ('sizes', 1), ('hardly', 1)])\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0c6UrZteh89","outputId":"67fe9553-6c31-43c0-a1e4-6d0b9b61ff6d","executionInfo":{"status":"ok","timestamp":1684949696350,"user_tz":-360,"elapsed":3837,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":123,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"]}]},{"cell_type":"code","source":["# import tensorflow as tf\n","# from transformers import TFAutoModel, AutoTokenizer\n","\n","# def define_model(length, vocab_size):\n","#     # channel 1\n","#     inputs1 = tf.keras.layers.Input(shape=(length,))\n","#     embedding1 = tf.keras.layers.Embedding(vocab_size, 100)(inputs1)\n","#     conv1 = tf.keras.layers.Conv1D(filters=32, kernel_size=4, activation='relu')(embedding1)\n","#     drop1 = tf.keras.layers.Dropout(0.5)(conv1)\n","#     pool1 = tf.keras.layers.MaxPooling1D(pool_size=2)(drop1)\n","#     flat1 = tf.keras.layers.Flatten()(pool1)\n","#     # channel 2\n","#     inputs2 = tf.keras.layers.Input(shape=(length,))\n","#     tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","#     bert_model = TFAutoModel.from_pretrained('bert-base-uncased')\n","#     input_ids = tf.keras.layers.Input(shape=(length,), dtype=tf.int32, name=\"input_ids\")\n","#     bert_embedding = bert_model(input_ids)[0]\n","#     pooled_output = bert_embedding[:, 0, :]\n","#     dense2 = tf.keras.layers.Dense(100, activation='relu')(pooled_output)\n","#     # channel 3\n","#     inputs3 = tf.keras.layers.Input(shape=(length,))\n","#     embedding3 = tf.keras.layers.Embedding(vocab_size, 100)(inputs3)\n","#     lstm3 = tf.keras.layers.LSTM(64)(embedding3)\n","#     dense3 = tf.keras.layers.Dense(100, activation='relu')(lstm3)\n","#     # merge\n","#     merged = tf.keras.layers.concatenate([flat1, dense2, dense3])\n","#     # interpretation\n","#     dense4 = tf.keras.layers.Dense(10, activation='relu')(merged)\n","#     outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense4)\n","#     model = tf.keras.models.Model(inputs=[inputs1, input_ids, inputs3], outputs=outputs)\n","#     # compile\n","#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","#     # summarize\n","#     print(model.summary())\n","#     return model"],"metadata":{"id":"cDGoy95cefZ9","executionInfo":{"status":"ok","timestamp":1684949696351,"user_tz":-360,"elapsed":10,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":124,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from transformers import TFAutoModel, AutoTokenizer\n","from gensim.models import KeyedVectors\n","\n","def define_model(length, vocab_size, word2vec_model_path):\n","    # channel 1\n","    inputs1 = tf.keras.layers.Input(shape=(length,), dtype=tf.int32)\n","    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","    input_ids = tf.keras.layers.Input(shape=(length,), dtype=tf.int32)\n","    bert_model = TFAutoModel.from_pretrained('bert-base-uncased')\n","    bert_output = bert_model(input_ids)[0] # use only the first tensor returned by the BERT model\n","    pooled_output = bert_output[:, 0, :]\n","    dense1 = tf.keras.layers.Dense(100, activation='relu')(pooled_output)\n","\n","    # channel 2\n","    inputs2 = tf.keras.layers.Input(shape=(length,))\n","    word2vec_model = KeyedVectors.load_word2vec_format(word2vec_model_path, binary=True)\n","    vocab_size = min(vocab_size, len(word2vec_model.key_to_index)) # adjust vocab_size based on actual vocabulary size\n","    embedding_matrix = np.zeros((vocab_size, word2vec_model.vector_size))\n","    for word, index in word2vec_model.key_to_index.items():\n","        if index >= vocab_size:\n","            continue\n","        embedding_matrix[index] = word2vec_model[word]\n","    embedding2 = tf.keras.layers.Embedding(vocab_size, word2vec_model.vector_size, weights=[embedding_matrix], trainable=False)(inputs2)\n","    conv2 = tf.keras.layers.Conv1D(filters=32, kernel_size=4, activation='relu')(embedding2)\n","    drop2 = tf.keras.layers.Dropout(0.5)(conv2)\n","    pool2 = tf.keras.layers.MaxPooling1D(pool_size=2)(drop2)\n","    flat2 = tf.keras.layers.Flatten()(pool2)\n","\n","    # channel 3\n","    inputs3 = tf.keras.layers.Input(shape=(length,))\n","    embedding3 = tf.keras.layers.Embedding(vocab_size, 100)(inputs3)\n","    lstm3 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(embedding3)\n","    dense3 = tf.keras.layers.Dense(100, activation='relu')(lstm3)\n","\n","    # merge\n","    merged = tf.keras.layers.concatenate([dense1, flat2, dense3])\n","\n","    # interpretation\n","    dense4 = tf.keras.layers.Dense(10, activation='relu')(merged)\n","    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense4)\n","\n","    model = tf.keras.models.Model(inputs=[input_ids, inputs2, inputs3], outputs=outputs)\n","\n","    # compile\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    # summarize\n","    print(model.summary())\n","\n","    return model\n","\n","WORD2VEC_MODEL = '/content/drive/MyDrive/NEEWWWWW/GoogleNews-vectors-negative300.bin'\n","model = define_model(length=100, vocab_size=10000, word2vec_model_path=WORD2VEC_MODEL)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1DqA7Ykq4wgj","outputId":"a60f929e-85be-4f75-d7ea-5b263892f8f9","executionInfo":{"status":"ok","timestamp":1684949756723,"user_tz":-360,"elapsed":60380,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":125,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model_6\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_27 (InputLayer)          [(None, 100)]        0           []                               \n","                                                                                                  \n"," embedding_12 (Embedding)       (None, 100, 300)     3000000     ['input_27[0][0]']               \n","                                                                                                  \n"," input_26 (InputLayer)          [(None, 100)]        0           []                               \n","                                                                                                  \n"," conv1d_6 (Conv1D)              (None, 97, 32)       38432       ['embedding_12[0][0]']           \n","                                                                                                  \n"," input_28 (InputLayer)          [(None, 100)]        0           []                               \n","                                                                                                  \n"," tf_bert_model_6 (TFBertModel)  TFBaseModelOutputWi  109482240   ['input_26[0][0]']               \n","                                thPoolingAndCrossAt                                               \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 100,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," dropout_265 (Dropout)          (None, 97, 32)       0           ['conv1d_6[0][0]']               \n","                                                                                                  \n"," embedding_13 (Embedding)       (None, 100, 100)     1000000     ['input_28[0][0]']               \n","                                                                                                  \n"," tf.__operators__.getitem_6 (Sl  (None, 768)         0           ['tf_bert_model_6[0][0]']        \n"," icingOpLambda)                                                                                   \n","                                                                                                  \n"," max_pooling1d_6 (MaxPooling1D)  (None, 48, 32)      0           ['dropout_265[0][0]']            \n","                                                                                                  \n"," bidirectional_6 (Bidirectional  (None, 128)         84480       ['embedding_13[0][0]']           \n"," )                                                                                                \n","                                                                                                  \n"," dense_24 (Dense)               (None, 100)          76900       ['tf.__operators__.getitem_6[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," flatten_6 (Flatten)            (None, 1536)         0           ['max_pooling1d_6[0][0]']        \n","                                                                                                  \n"," dense_25 (Dense)               (None, 100)          12900       ['bidirectional_6[0][0]']        \n","                                                                                                  \n"," concatenate_6 (Concatenate)    (None, 1736)         0           ['dense_24[0][0]',               \n","                                                                  'flatten_6[0][0]',              \n","                                                                  'dense_25[0][0]']               \n","                                                                                                  \n"," dense_26 (Dense)               (None, 10)           17370       ['concatenate_6[0][0]']          \n","                                                                                                  \n"," dense_27 (Dense)               (None, 1)            11          ['dense_26[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 113,712,333\n","Trainable params: 110,712,333\n","Non-trainable params: 3,000,000\n","__________________________________________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["word2vec_model_path = '/content/drive/MyDrive/NEEWWWWW/GoogleNews-vectors-negative300.bin'\n","print(vocab_size)\n","print(max_length)\n","# define model\n","model = define_model(max_length, vocab_size, word2vec_model_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X2GK1RnqcomF","outputId":"376283d5-2192-4e0a-daab-79a0d7ae4ff4","executionInfo":{"status":"ok","timestamp":1684949816833,"user_tz":-360,"elapsed":60123,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":126,"outputs":[{"output_type":"stream","name":"stdout","text":["619\n","17\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model_7\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_31 (InputLayer)          [(None, 17)]         0           []                               \n","                                                                                                  \n"," embedding_14 (Embedding)       (None, 17, 300)      185700      ['input_31[0][0]']               \n","                                                                                                  \n"," input_30 (InputLayer)          [(None, 17)]         0           []                               \n","                                                                                                  \n"," conv1d_7 (Conv1D)              (None, 14, 32)       38432       ['embedding_14[0][0]']           \n","                                                                                                  \n"," input_32 (InputLayer)          [(None, 17)]         0           []                               \n","                                                                                                  \n"," tf_bert_model_7 (TFBertModel)  TFBaseModelOutputWi  109482240   ['input_30[0][0]']               \n","                                thPoolingAndCrossAt                                               \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 17,                                                \n","                                768),                                                             \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," dropout_303 (Dropout)          (None, 14, 32)       0           ['conv1d_7[0][0]']               \n","                                                                                                  \n"," embedding_15 (Embedding)       (None, 17, 100)      61900       ['input_32[0][0]']               \n","                                                                                                  \n"," tf.__operators__.getitem_7 (Sl  (None, 768)         0           ['tf_bert_model_7[0][0]']        \n"," icingOpLambda)                                                                                   \n","                                                                                                  \n"," max_pooling1d_7 (MaxPooling1D)  (None, 7, 32)       0           ['dropout_303[0][0]']            \n","                                                                                                  \n"," bidirectional_7 (Bidirectional  (None, 128)         84480       ['embedding_15[0][0]']           \n"," )                                                                                                \n","                                                                                                  \n"," dense_28 (Dense)               (None, 100)          76900       ['tf.__operators__.getitem_7[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," flatten_7 (Flatten)            (None, 224)          0           ['max_pooling1d_7[0][0]']        \n","                                                                                                  \n"," dense_29 (Dense)               (None, 100)          12900       ['bidirectional_7[0][0]']        \n","                                                                                                  \n"," concatenate_7 (Concatenate)    (None, 424)          0           ['dense_28[0][0]',               \n","                                                                  'flatten_7[0][0]',              \n","                                                                  'dense_29[0][0]']               \n","                                                                                                  \n"," dense_30 (Dense)               (None, 10)           4250        ['concatenate_7[0][0]']          \n","                                                                                                  \n"," dense_31 (Dense)               (None, 1)            11          ['dense_30[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,946,813\n","Trainable params: 109,761,113\n","Non-trainable params: 185,700\n","__________________________________________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["test_docs, ytest = load_clean_dataset_test(vocab)"],"metadata":{"id":"sVZAWgocdBkN","executionInfo":{"status":"ok","timestamp":1684949816834,"user_tz":-360,"elapsed":27,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":127,"outputs":[]},{"cell_type":"code","source":["Xtest = encode_docs(tokenizer, max_length, test_docs)"],"metadata":{"id":"PONDZiTbdE3e","executionInfo":{"status":"ok","timestamp":1684949816835,"user_tz":-360,"elapsed":27,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":128,"outputs":[]},{"cell_type":"code","source":["# # fit model\n","# model.fit([Xtrain,Xtrain,Xtrain], ytrain, batch_size=32, epochs=5)"],"metadata":{"id":"Q90lr9yxcvJ8","executionInfo":{"status":"ok","timestamp":1684949816835,"user_tz":-360,"elapsed":27,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":129,"outputs":[]},{"cell_type":"code","source":["# fit model\n","model.fit([Xtrain,Xtrain,Xtrain], ytrain, validation_data=([Xtest,Xtest,Xtest], ytest), batch_size=6, epochs=30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_HoQlQmBJel6","outputId":"64ebcb2c-e41e-4e7d-8bb7-b32b51f5320c","executionInfo":{"status":"ok","timestamp":1684950109537,"user_tz":-360,"elapsed":292728,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":130,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["67/67 [==============================] - 69s 250ms/step - loss: 0.7233 - accuracy: 0.4950 - val_loss: 0.9964 - val_accuracy: 0.5000\n","Epoch 2/30\n","67/67 [==============================] - 11s 171ms/step - loss: 0.6994 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 3/30\n","67/67 [==============================] - 7s 108ms/step - loss: 0.6932 - accuracy: 0.4875 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 4/30\n","67/67 [==============================] - 7s 109ms/step - loss: 0.6607 - accuracy: 0.6225 - val_loss: 0.5389 - val_accuracy: 0.7900\n","Epoch 5/30\n","67/67 [==============================] - 6s 84ms/step - loss: 0.2326 - accuracy: 0.9300 - val_loss: 0.4270 - val_accuracy: 0.8500\n","Epoch 6/30\n","67/67 [==============================] - 8s 117ms/step - loss: 0.0714 - accuracy: 0.9700 - val_loss: 0.4774 - val_accuracy: 0.8700\n","Epoch 7/30\n","67/67 [==============================] - 6s 84ms/step - loss: 0.0302 - accuracy: 0.9900 - val_loss: 0.6531 - val_accuracy: 0.8800\n","Epoch 8/30\n","67/67 [==============================] - 7s 107ms/step - loss: 0.0234 - accuracy: 0.9950 - val_loss: 0.5606 - val_accuracy: 0.8900\n","Epoch 9/30\n","67/67 [==============================] - 6s 93ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6733 - val_accuracy: 0.8900\n","Epoch 10/30\n","67/67 [==============================] - 7s 105ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7404 - val_accuracy: 0.8900\n","Epoch 11/30\n","67/67 [==============================] - 7s 100ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.6001 - val_accuracy: 0.8700\n","Epoch 12/30\n","67/67 [==============================] - 6s 93ms/step - loss: 0.0120 - accuracy: 0.9975 - val_loss: 0.6499 - val_accuracy: 0.8800\n","Epoch 13/30\n","67/67 [==============================] - 8s 116ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.8700\n","Epoch 14/30\n","67/67 [==============================] - 6s 90ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7871 - val_accuracy: 0.8800\n","Epoch 15/30\n","67/67 [==============================] - 8s 113ms/step - loss: 9.4061e-04 - accuracy: 1.0000 - val_loss: 0.8024 - val_accuracy: 0.8800\n","Epoch 16/30\n","67/67 [==============================] - 6s 85ms/step - loss: 2.8657e-04 - accuracy: 1.0000 - val_loss: 0.8174 - val_accuracy: 0.8800\n","Epoch 17/30\n","67/67 [==============================] - 8s 115ms/step - loss: 2.1194e-04 - accuracy: 1.0000 - val_loss: 0.8394 - val_accuracy: 0.8800\n","Epoch 18/30\n","67/67 [==============================] - 6s 84ms/step - loss: 1.8007e-04 - accuracy: 1.0000 - val_loss: 0.8577 - val_accuracy: 0.8800\n","Epoch 19/30\n","67/67 [==============================] - 6s 97ms/step - loss: 1.5009e-04 - accuracy: 1.0000 - val_loss: 0.8730 - val_accuracy: 0.8800\n","Epoch 20/30\n","67/67 [==============================] - 7s 105ms/step - loss: 1.2626e-04 - accuracy: 1.0000 - val_loss: 0.8883 - val_accuracy: 0.8800\n","Epoch 21/30\n","67/67 [==============================] - 6s 87ms/step - loss: 1.0777e-04 - accuracy: 1.0000 - val_loss: 0.9039 - val_accuracy: 0.8800\n","Epoch 22/30\n","67/67 [==============================] - 7s 110ms/step - loss: 9.4316e-05 - accuracy: 1.0000 - val_loss: 0.9163 - val_accuracy: 0.8800\n","Epoch 23/30\n","67/67 [==============================] - 6s 87ms/step - loss: 8.7324e-05 - accuracy: 1.0000 - val_loss: 0.9288 - val_accuracy: 0.8800\n","Epoch 24/30\n","67/67 [==============================] - 7s 111ms/step - loss: 7.7481e-05 - accuracy: 1.0000 - val_loss: 0.9401 - val_accuracy: 0.8800\n","Epoch 25/30\n","67/67 [==============================] - 6s 87ms/step - loss: 7.0322e-05 - accuracy: 1.0000 - val_loss: 0.9488 - val_accuracy: 0.8800\n","Epoch 26/30\n","67/67 [==============================] - 7s 105ms/step - loss: 6.2991e-05 - accuracy: 1.0000 - val_loss: 0.9597 - val_accuracy: 0.8800\n","Epoch 27/30\n","67/67 [==============================] - 6s 93ms/step - loss: 5.9354e-05 - accuracy: 1.0000 - val_loss: 0.9693 - val_accuracy: 0.8800\n","Epoch 28/30\n","67/67 [==============================] - 7s 98ms/step - loss: 5.1577e-05 - accuracy: 1.0000 - val_loss: 0.9775 - val_accuracy: 0.8800\n","Epoch 29/30\n","67/67 [==============================] - 7s 100ms/step - loss: 4.9570e-05 - accuracy: 1.0000 - val_loss: 0.9865 - val_accuracy: 0.8800\n","Epoch 30/30\n","67/67 [==============================] - 6s 87ms/step - loss: 4.6070e-05 - accuracy: 1.0000 - val_loss: 0.9949 - val_accuracy: 0.8800\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1811899690>"]},"metadata":{},"execution_count":130}]},{"cell_type":"code","source":["# evaluate model on training dataset\n","_, acc = model.evaluate([Xtrain,Xtrain,Xtrain], ytrain, verbose=0)\n","print(' Train Accuracy: %f' % (acc*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nob_FVDadHld","outputId":"c8b0b287-cf50-4343-dc1d-c2e8fcf3f6fa","executionInfo":{"status":"ok","timestamp":1684950110628,"user_tz":-360,"elapsed":1097,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":131,"outputs":[{"output_type":"stream","name":"stdout","text":[" Train Accuracy: 100.000000\n"]}]},{"cell_type":"code","source":["# evaluate model on test dataset\n","_, acc = model.evaluate([Xtest,Xtest,Xtest], ytest, verbose=0)\n","print( ' Test Accuracy: %f ' % (acc*100))\n","     "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JhPsb9FBdMQ2","outputId":"8849e526-6513-43db-bfb5-086242fccdf1","executionInfo":{"status":"ok","timestamp":1684950111268,"user_tz":-360,"elapsed":643,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":132,"outputs":[{"output_type":"stream","name":"stdout","text":[" Test Accuracy: 88.000000 \n"]}]},{"cell_type":"code","source":["model.save('/content/gdrive/My Drive/sent_model_multi_input.h5')"],"metadata":{"id":"hLYq22qzgwpt","executionInfo":{"status":"ok","timestamp":1684950124265,"user_tz":-360,"elapsed":13002,"user":{"displayName":"S.M. Ashraful HASAN","userId":"00424401101905997672"}}},"execution_count":133,"outputs":[]}]}